{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7da5fea",
   "metadata": {},
   "source": [
    "# Modelo de Ising-Kawasaki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e241f",
   "metadata": {},
   "source": [
    "En este documento se presenta un desglose completo del código de un modelo de Ising basado en la dinámica de Kawasaki. El código se ha dividido en celdas principalmente para facilitar la explicación del contenido de las mismas, ya que en realidad, para obtener resultados del programa la celda que tiene que ejecutarse el la última de todas (y todas las anteriores). Ésto se ha hecho con el propósito de facilitar la manipulación del mismo, sin tener q desplazarse a celdas anteriores para modificar parámetros, o graficar observables de ningún tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79da487",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "El enfoque para este modelo es muy similar al del modelo clásico de Ising (dinámica de Glauber), donde simplemente aplicamos la dinámica de kawasaki. La principal diferencia en términos generales, es que como vamos a ver en este caso, al intercambiar espines, la magnetización total del sistema va a conservarse en todos los casos. La energía por otro lado, al aplicar el algoritmo de Metrópolis sí que va a disminuir hasta estabilizarse o por el contrario, alcanzará un estado estacionario. El que se dé un comportamiento u otro, estará muy estrechamente relacionado con el valor de la temperatura. Una vez modelado el sistema básico, se han calculadoalgunos observables y magnitudes de interés con el fin de extraer información valiosa del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996f84c",
   "metadata": {},
   "source": [
    "## Procedimiento computacional\n",
    "\n",
    "En el enunciado del problema se nos pedían 7 tareas a realizar como mínimo en el modelo. A lo largo de esta sección se desglosará como se han enfrentado dichas tareas y se explicará el procedimiento. Las tareas en cuestión son:\n",
    "\n",
    "1. Simular para varios valores de la temperatura la dinamica de este modelo. Representar varios fotogramas asociados a varias temperaturas.\n",
    "\n",
    "2. Obtener la curva de magnetizacion por partícula calculada ‘por dominios’ como funcion de la temperatura para varios tamanos del sistema (e.g. N = 32, 64, 128) promediando sobre un numero suficiente de pasos Monte Carlo para que el error sea razonablemente pequeno. Dicho promedio ‘por dominios’ se realiza –en caso de una magnetizacion inicial nula– calculando la magnetización en cada una de las mitades (superior e inferior) del sistema.\n",
    "\n",
    "3. Calcular densidad de partículas promedio en la direccion y para varias temperaturas.\n",
    "\n",
    "4. Calcular la energía media por partícula como funcion de la temperatura para los diferentes tamaños.\n",
    "\n",
    "5. Calcular el calor específico a partir de las fluctuaciones de la energía,\n",
    "\n",
    "$$\n",
    "c_N = \\frac{1}{N^2 T^2} \\left[ \\langle E^2 \\rangle - \\langle E \\rangle^2 \\right]\n",
    "$$\n",
    "\n",
    "como funcion de la temperatura para los diferentes tamaños y determinar la temperatura crítica. Para estimar\n",
    "dicha temperatura se ha de obtener, para cada valor del tamaño N, el maximo del calor específico, $\\text{T}_{c}\\text{(N)}$, y\n",
    "estudiar su comportamiento con N para extrapolar su valor en el l ́ımite N → ∞.\n",
    "\n",
    "6. Calcular la susceptibilidad magnética a partir de las fluctuaciones de la magnetización en cada dominio,\n",
    "\n",
    "$$\n",
    "\\chi_N = \\frac{1}{N^2 T} \\left[ \\langle M^2 \\rangle - \\langle M \\rangle^2 \\right]\n",
    "$$\n",
    "\n",
    "y determinar la temperatura crítica. Para estimar dicha temperatura se ha de obtener, para cada valor del tamaño N, el maximo de la susceptibilidad magnética, $\\text{T}_{c}\\text{(N)}$, y estudiar su comportamiento con N para extrapolar su valor en el límite N → ∞.\n",
    "\n",
    "7. Realizar los puntos 1-6 anteriores partiendo de una magnetizacion no nula. Recordemos que la magnetización por partícula puede tomar valores entre −1 y 1, i.e. m ∈ [−1, 1]. Por tanto si fijamos m = $\\text{m}_0$ el promedio ‘por dominios’ de la magnetizacion se realizará, en este caso, promediando por separado la fracción x = (1 + $\\text{m}_0$)/2\n",
    "(con x ∈ [0, 1]) inferior del sistema, y la fraccion 1 − x superior del mismo. De esta manera, para T → 0,\n",
    "tendremos:\n",
    "\n",
    "$$\n",
    "m = x(+1) + (1 − x)(−1) = m_0.\n",
    "$$\n",
    "\n",
    "Observamos que si $\\text{m}_0$ = 0 tenemos que x = 1/2, es decir, tenemos que promediar la magnetizacion por separado en la mitad inferior y en la mitad superior del sistema, como hab ́ıamos explicado en el punto 2. Representar la curva de magnetizacion frente a temperatura y comprobar que es discontinua por debajo de una temperatura crítica. Dicha discontinuidad se hara más pronunciada conforme el tamaño del sistema sea mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2622b49",
   "metadata": {},
   "source": [
    "### Celda 1:\n",
    "\n",
    "En la primera celda, como suele ser habitual se han incluido los imports necesarios para la ejecución del código. Algunos que nos pueden llamar la atención son _time_, _tqdm_, _os_, _h5py_, _subprocess_, _threading_ y _re_. _Time_ y _tqdm_, por un lado, se han utilizado para el cálculo del tiempo de ejecución y la generación de una barra de progreso, respectivamente. Obviamente esto en innecesario pero útil para saber si una ejecución va a tardar 2 minutos o 3 horas. Por otro lado, _os_ se ha utilizado para obtener información del dispositivo y detectar el número de hebras disponibles (aunque como veremos no ha sido de utilidad). Y por último _subprocess_, _threading_ y _re_, se utilizan para la generación del video de la simulación. \n",
    "\n",
    "Tras esto definimos un rng seguro, basado en la entropía del sistema para una mayor aleatoriedad. La ventaja de este es que se podría utilizar para paralelizar con numba o PyOMP si fuera posible. \n",
    "\n",
    "Finalmente, se define la función _establecer_numero_hilos(threads_percentage)_, que analiza la CPU del usuario, para determinar el número de hebras, y utiliza un porcentaje de los mismo, _threads_percentage_, elegido por el usuario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f8ccc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: Imports, semilla y configuración de hilos\n",
    "\n",
    "import numpy as np                      # Celdas: 2,3,4,5,6,7,8 (NP arrays, random choice with rng)\n",
    "import matplotlib.pyplot as plt         # Celdas: 2,6,7,8 (Visualización, gráficos, animación)\n",
    "import time                             # Celda: 5 (Medición de tiempos)\n",
    "from tqdm import tqdm                   # Celda: 5 (Barra de progreso, opcional)\n",
    "from numba import njit, set_num_threads, get_num_threads\n",
    "import os                               # Para obtener el número de hilos disponibles\n",
    "import h5py                             # Para guardar resultados en formato HDF5\n",
    "import subprocess, threading, re, math # Última celda para la generación del video\n",
    "\n",
    "np.set_printoptions(threshold=np.inf, linewidth=200)\n",
    "\n",
    "# ─── Configuración de semilla para reproducibilidad ──────────────────────────\n",
    "seed = None                             # None = usar entropía del sistema\n",
    "rng  = np.random.default_rng(seed)      # PCG64 RNG: seguro y adecuado para simulaciones\n",
    "\n",
    "def establecer_numero_hilos(threads_percentage):\n",
    "    #Establecemos el número de hilos a usar asegurándonos de que no exceda el número de hilos disponibles ni sea menor a 1\n",
    "    n_threads_available = os.cpu_count()\n",
    "    if n_threads_available is None:\n",
    "        n_threads_available = 1  # Si no se puede determinar, usar al menos 1 hilo\n",
    "    threads_percentage = max(1, min(100, threads_percentage))\n",
    "    set_num_threads(int(n_threads_available*(threads_percentage / 100.0)))\n",
    "    n_threads = get_num_threads()\n",
    "    print(f\"Usando {n_threads} hilos de {n_threads_available} disponibles ({threads_percentage}%).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb9344",
   "metadata": {},
   "source": [
    "### Celda 2:\n",
    "\n",
    "Aquí se definen la mayoría de los observables termodinámicos del sistema. En primer lugar tenemos dos pares de funciones muy parecidas; _single_energy(config, J)_ y _new_energy(J, frames:np.ndarray)_, y _single_magnetization(config: np.ndarray)_ y _new_magnetization(frames: np.ndarray)_. Estas calculan la energía y la magnetización, de una sola configuración y de un vector de configuraciones, respectivamente. Las cuatro son muy simples, son una aplicación directa de la definición de estos observables. \n",
    "\n",
    "Por otro lado tenemos _domain_magnetization(frames: np.ndarray, density)_, que calcula la magnetización por dominios. Para ello define un límite, que detemina el tamaño de los diferentes dominios (se definen los dominios como las regiones de espines $\\pm$ 1 cuando el sistema se estabiliza para T $\\rightarrow$ 0). Esta función devuelve un array de magnetizaciones de ambos dominios.\n",
    "\n",
    "Se definen también dos funciones que no son observables exactamente, _linear_regression_slope(x, y)_ y _acceptance_slope(acceptance: np.ndarray, threshold: float)_. La primera simplemente calcula una regresión lineal y devuelve la pendiente, y la segunda, compara esa pendiente con un umbral _threshold_, si es menor devuelve True, si no False. Esto se utiliza para la condición de parada del programa. Para ello necesita definir otra función, _calculate_acceptance(frames: np.ndarray)_, que calcula la tasa de aceptación en cada frame (tasa de éxito de intercambio de espines en cada barrido completo). Cuando el módulo de la pendiente de la tasa de aceptación se acerque a 0 (cuando el sistema se estabilice), la simulación se detendrá. \n",
    "\n",
    "Por otro lado, se calculan también el calor específico y la susceptibilidad magnética, _specific_heat(energy: np.ndarray, temperature: float, L: int)_ y _magnetic_susceptibility(domain_magnetization: np.ndarray, temperature: float, L: int)_. Por último, tenemos la densidad media de partículas en el eje y, _calcular_densidad_party(frames: np.ndarray)_. Esto es básicamente la densidad de espines con valor +1, en función de y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e2758ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: Definición de algunas funciones de observables\n",
    "\n",
    "def single_energy(config, J):\n",
    "    \"\"\"\n",
    "    Calcula la energía total del modelo de Ising 2D con contorno periódico.\n",
    "    \"\"\"\n",
    "    # Enlaces derecha e inferior para contar cada par una sola vez\n",
    "    right = np.roll(config, -1, axis=1)\n",
    "    down  = np.roll(config, -1, axis=0)\n",
    "    energy = -J * np.sum(config * (right + down))\n",
    "    return energy\n",
    "\n",
    "\n",
    "def new_energy(J, frames:np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calcula la energía total del modelo de Ising 2D con contorno periódico.\n",
    "    \"\"\"\n",
    "    # Enlaces derecha e inferior para contar cada par una sola vez\n",
    "    nframes, H, W = frames.shape\n",
    "    energy = np.zeros(nframes, dtype=np.float64)  # Array para almacenar la energía de cada frame\n",
    "    for frame in range(nframes):\n",
    "        config = frames[frame, :, :]\n",
    "        right = np.roll(config, -1, axis=1)\n",
    "        down  = np.roll(config, -1, axis=0)\n",
    "        energy[frame] = -J * np.sum(config * (right + down))\n",
    "    return energy\n",
    "\n",
    "\n",
    "def single_magnetization(config: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la magnetización total del sistema.\n",
    "    \"\"\"\n",
    "    H, W = config.shape\n",
    "    return np.sum(config) / (H * W)  # Magnetización normalizada\n",
    "\n",
    "\n",
    "@njit\n",
    "def new_magnetization(frames: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calcula la magnetización total del sistema para cada frame.\n",
    "    \"\"\"\n",
    "    nframes, H, W = frames.shape\n",
    "    magnetizations = np.zeros(nframes, dtype=np.float64)  # Array para almacenar la magnetización de cada frame\n",
    "    for frame in range(nframes):\n",
    "        config = frames[frame, :, :]\n",
    "        magnetizations[frame] = np.sum(config)/(H*W)\n",
    "    return magnetizations\n",
    "\n",
    "\n",
    "def domain_magnetization(frames: np.ndarray, density) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calcula la magnetización del sistema para el dominio superior e inferior. Para ello esta función\n",
    "    las calcula y las devuelve en un array de dos dimensiones, 2xnframes, donde la primera fila\n",
    "    corresponde a la magnetización del dominio superior y la segunda fila a la del dominio inferior.\n",
    "    \"\"\"\n",
    "    nframes, H, W = frames.shape\n",
    "    magnetizations = np.zeros((2, nframes), dtype=np.float64)  # Array para almacenar la magnetización de cada frame\n",
    "    lim = int(np.rint(H*density))\n",
    "    for frame in range(nframes):\n",
    "        config = frames[frame, :, :]\n",
    "        magnetizations[0, frame] = np.sum(config[0:(H - lim), :])/((H - lim)*W)\n",
    "        magnetizations[1, frame] = np.sum(config[(H - lim):H, :])/(lim*W)\n",
    "    return magnetizations\n",
    "\n",
    "\n",
    "def linear_regression_slope(x, y):\n",
    "    \"\"\"\n",
    "    Calcula la pendiente de la recta de regresión lineal ajustada a los puntos (x, y)\n",
    "    usando la función np.polyfit de NumPy.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    x : array_like, shape (n,)\n",
    "        Vector de coordenadas independientes.\n",
    "    y : array_like, shape (n,)\n",
    "        Vector de coordenadas dependientes.\n",
    "\n",
    "    Devuelve\n",
    "    -------\n",
    "    slope : float\n",
    "        Pendiente de la recta de regresión lineal.\n",
    "\n",
    "    Lanza\n",
    "    -----\n",
    "    ValueError\n",
    "        Si x e y no tienen la misma longitud o si n < 2.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if x.shape != y.shape:\n",
    "        raise ValueError(\"Los vectores x e y deben tener la misma longitud\")\n",
    "    if x.size < 2:\n",
    "        raise ValueError(\"Se necesitan al menos dos puntos para ajustar una recta\")\n",
    "\n",
    "    # np.polyfit devuelve [pendiente, intercepto] para grado=1\n",
    "    slope, _ = np.polyfit(x, y, 1)\n",
    "    return slope\n",
    "\n",
    "\n",
    "def acceptance_slope(acceptance: np.ndarray, threshold: float) -> bool:\n",
    "    \"\"\"\n",
    "    Comprueba la pendiente de la tasa de aceptación y si es menor que un umbral toma valor True.\n",
    "    \"\"\"\n",
    "    x = np.arange(acceptance.size)\n",
    "    slope = abs(linear_regression_slope(x, acceptance))\n",
    "    if slope < threshold:\n",
    "        print(f\"Pendiente de la tasa de aceptación: {slope} < {threshold:.4f}\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def specific_heat(energy: np.ndarray, temperature: float, L: int) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el calor específico a partir de la energía y la temperatura.\n",
    "    \"\"\"\n",
    "    frames = len(energy)                                                # Número de frames\n",
    "    stabilized_energy = energy[int(frames*0.75):]                       # Tomamos el 25% final de los frames para medir solo la parte estable de la energía\n",
    "    Squared_energy = np.mean(stabilized_energy**2)                      # <E^2>\n",
    "    Mean_energy= np.mean(stabilized_energy)                             # <E>\n",
    "    SH = (Squared_energy-Mean_energy**2)/((L**2)*(temperature**2))      # Calor específico\n",
    "    return SH                                                           # Devolvemos el calor específico como un número flotante, que es la media del calor específico de todos los frames estables.\n",
    "\n",
    "\n",
    "def magnetic_susceptibility(domain_magnetization: np.ndarray, temperature: float, L: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calcula la susceptibilidad magnética a partir de la magnetización del dominio superior e inferior.\n",
    "    \"\"\"\n",
    "    frames = domain_magnetization.shape[0]                                          # Número de frames\n",
    "    stabilized_magnetization = domain_magnetization[:, int(frames*0.75):]           # Tomamos el 25% final de los frames para medir solo la parte estable de la magnetización\n",
    "    UpperMagn = stabilized_magnetization[0, :]\n",
    "    LowerMagn = stabilized_magnetization[1, :]\n",
    "    Mean_Upper_Magn = np.mean(UpperMagn)\n",
    "    Mean_Lower_Magn = np.mean(LowerMagn)\n",
    "    Squared_Mean_Upper_Magn = np.mean(UpperMagn**2)\n",
    "    Squared_Mean_Lower_Magn = np.mean(LowerMagn**2)\n",
    "    Upper_MS = (Squared_Mean_Upper_Magn-(Mean_Upper_Magn**2))/((L**2)*temperature)\n",
    "    Lower_MS = (Squared_Mean_Lower_Magn-(Mean_Lower_Magn**2))/((L**2)*temperature)\n",
    "    Mean_MS = (Upper_MS + Lower_MS)/2\n",
    "\n",
    "    return Mean_MS\n",
    "\n",
    "\n",
    "@njit\n",
    "def calculate_acceptance(frames: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    nframes, H, W = frames.shape\n",
    "    # True donde el espín cambió respecto al sweep anterior\n",
    "    changes = frames[1:] != frames[:-1]               # shape (nframes-1, H, W)\n",
    "    diff_counts = changes.reshape(nframes-1, -1).sum(axis=1)\n",
    "    # Cada swap válido intercambia dos posiciones\n",
    "    accepted_swaps = diff_counts / 2\n",
    "    # Nº de intentos de swap por sweep ≈ H*W\n",
    "    attempts = H * W\n",
    "    acceptance = accepted_swaps / attempts\n",
    "    return acceptance\n",
    "\n",
    "\n",
    "@njit\n",
    "def calcular_densidad_party(frames: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calcula la densidad de partículas en cada frame.\n",
    "    \"\"\"\n",
    "    nframes, H, W = frames.shape                # Obviamente H, W = L, L\n",
    "    config = frames[-1, :, :]                   # Última columna de cada frame\n",
    "    density= np.zeros(H, dtype=np.float64)      # Array para almacenar la densidad de partículas\n",
    "\n",
    "    # Sumamos los espines a lo largo del eje x, y lo almacenamos en un array\n",
    "    for i in range(H):\n",
    "        s = 0\n",
    "        for j in range(W):\n",
    "            s += (config[i, j] + 1)/2           # Convertimos espines -1, +1 a densidad 0, 1\n",
    "        density[i] = s/W                        # Densidad media de partículas en la fila i\n",
    "    return density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ba82b",
   "metadata": {},
   "source": [
    "### Celda 3:\n",
    "\n",
    "En esta celda se definen tres métodos para generar la configuración inicial de espines en una red cuadrada de tamaño $L \\times L$ con una densidad dada de espines $+1$. Cada función garantiza que la magnetización total cumpla con el valor deseado y permite distintos tipos de condiciones de contorno o configuraciones asimétricas:\n",
    "\n",
    "- _random_config_boundary(L, density)_: \n",
    "  1. Crea una matriz config de tamaño $L\\times L$ inicializada con todos los espines en $+1$.  \n",
    "  2. Fija la fila superior a $-1$ para imponer condiciones de contorno fijas en la dirección vertical.  \n",
    "  3. Inserta espines $-1$ aleatoriamente (excluyendo la fila superior) hasta que la magnetización total normalizada  \n",
    "     $$\n",
    "       m = \\frac{1}{L^2}\\sum_{i,j} s_{i,j}\n",
    "     $$  \n",
    "     coincida con el valor deseado $2\\,\\text{density}-1$.  \n",
    "\n",
    "- _random_config_non_boundary(L, density)_: \n",
    "  1. Crea una matriz config con todos los espines en $+1$.  \n",
    "  2. Inserta espines $-1$ en posiciones completamente aleatorias (toda la red) hasta alcanzar la magnetización  \n",
    "     normalizada $2\\,\\text{density} - 1$, sin ninguna fila fija (condiciones periódicas en ambas direcciones).  \n",
    "\n",
    "- _asimmetric_config(L, density)_:  \n",
    "  1. Inicializa la red con todos los espines en $+1$.  \n",
    "  2. Calcula el número total de espines $-1$ necesario: $(1-\\text{density})\\times L^2$.  \n",
    "  3. Recorre la matriz fila por fila, colocando \\(-1\\) de forma determinista en las primeras posiciones hasta  \n",
    "     agotar el número calculado, obteniendo así una **configuración asimétrica**.  \n",
    "\n",
    "- _init_config(destino, L, density, Boundary_conditions, Asimmetric)_:  \n",
    "  1. Elige una de las tres funciones anteriores en función de los flags Boundary_conditions y Asimmetric.  \n",
    "  2. Genera la configuración inicial config.  \n",
    "  3. Dibuja la red en escala de grises con matplotlib y la guarda en el fichero PNG indicado por destino.  \n",
    "  4. Devuelve la matriz config para usarla en el resto de la simulación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bd7305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3: Inicialización de configuraciones\n",
    "\n",
    "def random_config_boundary(L, density):   \n",
    "    config = np.ones((L, L), dtype=int)\n",
    "    config[0, :] = -1  # Fila superior\n",
    "    while single_magnetization(config) != (2*density - 1):  # Aseguramos que la magnetización sea igual a la densidad deseada\n",
    "        i, j = np.random.randint(1, L-1), np.random.randint(0, L)  # Elegir un espín aleatorio\n",
    "        config[i, j] = -1\n",
    "    return config\n",
    "\n",
    "\n",
    "def random_config_non_boundary(L, density):   \n",
    "    config = np.ones((L, L), dtype=int)      # Inicializar toda la red con espines +1\n",
    "    while single_magnetization(config) != (2*density - 1):  # Aseguramos que la magnetización sea igual a la densidad deseada\n",
    "        i, j = np.random.randint(0, L), np.random.randint(0, L)  # Elegir un espín aleatorio\n",
    "        config[i, j] = -1\n",
    "    return config\n",
    "\n",
    "\n",
    "def asimmetric_config(L, density):\n",
    "    config = np.ones((L, L), dtype=int)      # Inicializar toda la red con espines 1\n",
    "\n",
    "    # Ahora simplemente hacemos que el porcentaje \"density\" superior sean -1s:\n",
    "    # Para ello la forma más sencilla es:\n",
    "    #   · Calcular el número de espines -1\n",
    "    #   · Recorrer la malla llenando de -1\n",
    "\n",
    "    DownSpins = (1-density)*L*L # Número de espines -1 a colocar\n",
    "\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            if DownSpins > 0:\n",
    "                config[i, j] = -1 \n",
    "                DownSpins += -1\n",
    "            else:\n",
    "                return config\n",
    "\n",
    "\n",
    "# Ahora creamos una función para guardar la configuración inicial en un archivo .png, y que devuelva la configuración\n",
    "def init_config(destino, L, density, Boundary_conditions, Asimmetric):\n",
    "    \"\"\"\n",
    "    Guarda la configuración inicial en un archivo .png.\n",
    "    \"\"\"\n",
    "    if not Asimmetric:\n",
    "        if Boundary_conditions:\n",
    "            config = random_config_boundary(L, density)  # Generar configuración aleatoria y fijar condiciones de frontera \n",
    "        else:\n",
    "            config = random_config_non_boundary(L, density)\n",
    "    else:\n",
    "        config = asimmetric_config(L, density)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(config, cmap='gray', interpolation='nearest')\n",
    "    plt.title('Configuración inicial aleatoria')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(destino, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026570f",
   "metadata": {},
   "source": [
    "### Celda 4:\n",
    "\n",
    "En esta celda se implementa la dinámica de Kawasaki mediante Numba (@njit) para maximizar el rendimiento. Se incluyen tres funciones principales:\n",
    "\n",
    "- _delta_E_kawasaki(config, i, j, k, l, J, L)_:\n",
    "  1. Dada una configuración config y dos posiciones vecinas $(i,j)$ y $(k,l)$, calcula la diferencia de energía $\\Delta E$ al intercambiar sus espines.  \n",
    "  2. Suma las contribuciones de los cuatro vecinos de cada espín (excluyendo el par intercambiado).  \n",
    "  3. Calcula la energía inicial  \n",
    "     $$\n",
    "       E_1 = s_{i,j}\\sum_{\\langle n\\rangle} s_n \\;+\\; s_{k,l}\\sum_{\\langle m\\rangle} s_m  \n",
    "     $$\n",
    "     y la energía tras el intercambio  \n",
    "     $$\n",
    "       E_2 = s_{k,l}\\sum_{\\langle n\\rangle} s_n \\;+\\; s_{i,j}\\sum_{\\langle m\\rangle} s_m  \n",
    "     $$  \n",
    "  4. Devuelve  \n",
    "     $$  \n",
    "       \\Delta E = -J\\,(E_2 - E_1)\\,.  \n",
    "     $$\n",
    "\n",
    "- _sweep_kawasaki_boundary(config, L, J, Beta)_:\n",
    "  1. Recorre $(L-2)\\times L$ intentos de intercambio, excluyendo las filas superior e inferior (bordes fijos).  \n",
    "  2. Para cada intento, elige un espín $(i,j)$ aleatorio en las filas intermedias.  \n",
    "  3. Selecciona un vecino $(n_i,n_j)$ mediante offsets aleatorios, cuidando no salirse de los bordes fijos.  \n",
    "  4. Si los dos espines difieren, calcula $\\Delta E$ y acepta el intercambio si $\\Delta E \\le 0$ o si  \n",
    "     $$  \n",
    "       \\exp(-\\Delta E\\,\\Beta) > \\mathrm{rand}()  \n",
    "     $$\n",
    "\n",
    "- _sweep_kawasaki_non_boundary(config, L, J, Beta)_  \n",
    "  1. Similar al anterior, pero recorre $L\\times L$ intentos y permite condiciones completamente periódicas (toda la red).  \n",
    "  2. No hay distinción de bordes; los offsets se eligen siempre entre los cuatro vecinos.  \n",
    "  3. Aplica la misma regla de aceptación de Metrópolis usando $\\Delta E$ y $\\Beta = 1/T$.  \n",
    "\n",
    "Este bloque optimizado en Numba acelera notablemente los barridos Monte Carlo al compilar estas funciones en código nativo.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "285b3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4: Dinámica de Kawasaki y funciones numba\n",
    "\n",
    "@njit\n",
    "def delta_E_kawasaki(config, i, j, k, l, J, L):\n",
    "    \"\"\"\n",
    "    Calcula el cambio de energía ΔE para un intercambio de espines en la dinámica de Kawasaki.\n",
    "    \"\"\"\n",
    "    # Calculamos los vecinos de (i, j) y (k, l) excluyendo el espín que se va a intercambiar\n",
    "    neighbors_ij = config[i,(j-1)%L] + config[(i-1)%L,j] + config[(i+1)%L,j] + config[i,(j+1)%L] - config[k, l]\n",
    "    neighbors_kl = config[k,(l-1)%L] + config[(k-1)%L,l] + config[(k+1)%L,l] + config[k,(l+1)%L] - config[i, j]\n",
    "\n",
    "    #Calculamos la energía de la configuración inicial\n",
    "    E_1 = config[i,j]*neighbors_ij + config[k,l]*neighbors_kl\n",
    "\n",
    "    #Calculamos la energía de la configuración final\n",
    "    E_2 = config[k,l]*neighbors_ij + config[i,j]*neighbors_kl\n",
    "\n",
    "    #Calculamos el cambio de energía\n",
    "    delta_E = -J*(E_2 - E_1)\n",
    "\n",
    "    return delta_E\n",
    "\n",
    "\n",
    "#Paso de la simulación\n",
    "\n",
    "@njit\n",
    "def sweep_kawasaki_boundary(config, L, J, Beta):\n",
    "    for k in range(((L-2)*L)):\n",
    "\n",
    "        #Seleccionamos un espín aleatorio (i, j) de la red excluyendo las filas superior e inferior\n",
    "        i, j = np.random.randint(1, L-1), np.random.randint(0, L)\n",
    "\n",
    "        # Escribimos el espin seleccionado en un archivo para depuración\n",
    "        # Definimos los offsets para los vecinos (arriba, abajo, izquierda, derecha)\n",
    "        offsets = np.array([(1, 0), (0, 1), (0, -1),  (-1, 0)], dtype=np.int64)\n",
    "\n",
    "        # Ahora seleccionamos un offset aleatorio que decidirá si escogemos un vecino arriba, abajo, izquierda o derecha\n",
    "        #Hay que mantener la condición de los espines superior e inferior.\n",
    "        # Entonces lo que hacemos es limitar los offsets a 3 si estamos en la fila superior o inferior, y a 4 si estamos en el resto de la red.\n",
    "        # Y luego forzamos que si está en la fila\n",
    "        if i == 1:\n",
    "            di, dj = offsets[np.random.randint(0, 3)]\n",
    "        elif i == L-2:\n",
    "            di, dj = offsets[np.random.randint(1, 4)]\n",
    "        else:\n",
    "            di, dj = offsets[np.random.randint(0, 4)]\n",
    "\n",
    "        # Ahora podemos calcular la posición exacta del espín vecino\n",
    "        ni, nj = (i + di) % L, (j + dj) % L\n",
    "\n",
    "        # Escribimos el espín vecino en el archivo para depuración\n",
    "        # Ahora que tenemos la posición del espín vecino, comprobamos que no sea el mismo espín (i, j) que el vecino (ni, nj)\n",
    "        if config[i, j] != config[ni, nj]:\n",
    "            delta_E = delta_E_kawasaki(config, i, j, ni, nj, J, L)\n",
    "\n",
    "            # Ahora que tenemos el ΔE, podemos decidir si aceptamos o no el movimiento\n",
    "            # La condición básicamente es que para ΔE <= 0, aceptamos el movimiento, ya que de ser así la probabilidad de aceptación es 1.\n",
    "            # Si ΔE > 0, aceptamos el movimiento con probabilidad p = exp(-ΔE/T), y lo más eficiente es generar un número aleatorio entre 0 y 1 y comparar con p,\n",
    "            # ya que si el número aleatorio es menor o igual que p, aceptamos el movimiento.\n",
    "            if delta_E <= 0 or np.random.rand() < np.exp(-delta_E * Beta):\n",
    "\n",
    "                # Intercambiar espines\n",
    "                config[i, j], config[ni, nj] = config[ni, nj], config[i, j]\n",
    "\n",
    "@njit\n",
    "def sweep_kawasaki_non_boundary(config, L, J, Beta):            \n",
    "    for k in range(L*L):\n",
    "\n",
    "        #Seleccionamos un espín aleatorio (i, j) de la red excluyendo las filas superior e inferior\n",
    "        i, j = np.random.randint(0, L), np.random.randint(0, L)\n",
    "\n",
    "        # Escribimos el espin seleccionado en un archivo para depuración\n",
    "        # Definimos los offsets para los vecinos (arriba, abajo, izquierda, derecha)\n",
    "        offsets = np.array([(1, 0), (0, 1), (0, -1),  (-1, 0)], dtype=np.int64)\n",
    "\n",
    "        # Ahora seleccionamos un offset aleatorio que decidirá si escogemos un vecino arriba, abajo, izquierda o derecha\n",
    "        #Hay que mantener la condición de los espines superior e inferior.\n",
    "        # Entonces lo que hacemos es limitar los offsets a 3 si estamos en la fila superior o inferior, y a 4 si estamos en el resto de la red.\n",
    "        # Y luego forzamos que si está en la fila\n",
    "        di, dj = offsets[np.random.randint(0, 4)]\n",
    "\n",
    "        # Ahora podemos calcular la posición exacta del espín vecino\n",
    "        ni, nj = (i + di) % L, (j + dj) % L\n",
    "\n",
    "        # Escribimos el espín vecino en el archivo para depuración\n",
    "        # Ahora que tenemos la posición del espín vecino, comprobamos que no sea el mismo espín (i, j) que el vecino (ni, nj)\n",
    "        if config[i, j] != config[ni, nj]:\n",
    "            delta_E = delta_E_kawasaki(config, i, j, ni, nj, J, L)\n",
    "\n",
    "            # Ahora que tenemos el ΔE, podemos decidir si aceptamos o no el movimiento\n",
    "            # La condición básicamente es que para ΔE <= 0, aceptamos el movimiento, ya que de ser así la probabilidad de aceptación es 1.\n",
    "            # Si ΔE > 0, aceptamos el movimiento con probabilidad p = exp(-ΔE/T), y lo más eficiente es generar un número aleatorio entre 0 y 1 y comparar con p,\n",
    "            # ya que si el número aleatorio es menor o igual que p, aceptamos el movimiento.\n",
    "            if delta_E <= 0 or np.random.rand() < np.exp(-delta_E * Beta):\n",
    "\n",
    "                # Intercambiar espines\n",
    "                config[i, j], config[ni, nj] = config[ni, nj], config[i, j]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec4ad21",
   "metadata": {},
   "source": [
    "### Celda 5:\n",
    "\n",
    "Esta celda contiene la función _plot_observables(destino, J, density)_, que:\n",
    "\n",
    "1. Carga los datos:\n",
    "   - Abre el archivo HDF5 configs.h5 en la carpeta destino y extrae el array frames de dimensiones (nframes, L, L).  \n",
    "   - Lee el atributo thin para conocer la frecuencia de guardado.\n",
    "\n",
    "2. _Tasa de aceptación:\n",
    "   - Calcula la tasa de aceptación en cada sweep usando calculate_acceptance(frames).  \n",
    "   - Crea el array sweeps multiplicando cada índice por thin.  \n",
    "   - Genera y guarda la gráfica _acceptance_rate.png_ de aceptación vs. sweep.\n",
    "\n",
    "3. Energía:  \n",
    "   - Calcula la energía de cada frame con new_energy(J, frames).  \n",
    "   - Ajusta el array de sweeps y dibuja la gráfica _energy.png_ de energía vs. sweep.\n",
    "\n",
    "4. Magnetización global:  \n",
    "   - Obtiene la magnetización por frame con new_magnetization(frames).  \n",
    "   - Dibuja la gráfica _magnetization.png_ de magnetización vs. sweep.\n",
    "\n",
    "5. Magnetización por dominios:  \n",
    "   - Calcula la magnetización del dominio superior e inferior usando _domain_magnetization(frames, density)_.  \n",
    "   - Dibuja _domain_magnetization.png_, con curvas separadas para cada dominio.\n",
    "\n",
    "6. Densidad de partículas en la dirección $y$:  \n",
    "   - Extrae la densidad con _calcular_densidad_party(frames)_.  \n",
    "   - Ajusta el eje vertical _y_array_ multiplicando por _thin_.  \n",
    "   - Dibuja _DensityAlongYAxis.png_ de densidad vs. posición _y_.\n",
    "\n",
    "7. Energía media por partícula:  \n",
    "   - Calcula el valor final de energía media por partícula  \n",
    "     $$\n",
    "       \\frac{E_{\\text{ultimo}}}{\\,L^2 \\cdot \\tfrac{1}{2}(m_{\\text{ultimo}}+1)}  \n",
    "     $$  \n",
    "   - Devuelve un diccionario con los observables clave:  \n",
    "     - _density_  \n",
    "     - _mean_energy_per_particle_  \n",
    "     - _energy_  \n",
    "     - _domain_magnetization_  \n",
    "\n",
    "Cada bloque de ploteo se encarga de cerrar la figura (_plt.close()_) para liberar memoria y evitar solapamiento de gráficos.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6668f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5: Definición función de ploteo de observables\n",
    "\n",
    "def plot_observables(destino, J, density):\n",
    "\n",
    "    # Primero de todo, vamos a cargar los datos de las configuraciones guardadas en el archivo HDF5\n",
    "    with h5py.File(os.path.join(destino, 'configs.h5'), 'r') as f:\n",
    "        frames = f['configs'][:]                    # np.ndarray (nframes, H, W)\n",
    "        thin = f.attrs['thin']                      # Frecuencia de guardado\n",
    "    nframes, H, W = frames.shape                    # nframes = saved_sweeps\n",
    "\n",
    "    # ─── Acceptance rate ────────────────────────────────\n",
    "\n",
    "    acceptance = calculate_acceptance(frames)\n",
    "    sweeps = np.arange(len(acceptance))             # Array de sweeps\n",
    "    for i in range(len(sweeps)):\n",
    "        sweeps[i] = sweeps[i]*thin\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(sweeps, acceptance, linestyle='-')\n",
    "    plt.xlabel('Sweep')\n",
    "    plt.ylabel('Acceptance rate')\n",
    "    plt.title('Evolución de la tasa de aceptación (Kawasaki)')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(destino, 'acceptance_rate.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # ─── Energía ────────────────────────────────\n",
    "\n",
    "    energies = new_energy(J, frames)                # Calcular energía de cada frame\n",
    "    n_sweeps_array = np.arange(len(energies))       # Array de sweeps\n",
    "    for i in range(nframes):\n",
    "        n_sweeps_array[i] = n_sweeps_array[i]*thin\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(n_sweeps_array, energies, linestyle='-')\n",
    "    plt.xlabel('Sweep')\n",
    "    plt.ylabel('Energía')\n",
    "    plt.title('Energía del sistema (Kawasaki)')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(destino, 'energy.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # ─── Magnetización ────────────────────────────────\n",
    "\n",
    "    magnetizations = new_magnetization(frames)                      # Calcular magnetización de cada frame\n",
    "    n_sweeps_array = np.arange(len(magnetizations))                 # Array de sweeps\n",
    "    for i in range(nframes):\n",
    "        n_sweeps_array[i] = n_sweeps_array[i]*thin\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(n_sweeps_array, magnetizations, linestyle='-')\n",
    "    plt.xlabel('Sweep')\n",
    "    plt.ylabel('Magnetización')\n",
    "    plt.title('Magnetización del sistema (Kawasaki)')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(destino, 'magnetization.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # ─── Magnetización del dominio superior e inferior ────────────────────────────────\n",
    "\n",
    "    domain_magnetizations = domain_magnetization(frames, density)   # Calcular magnetización del dominio superior e inferior\n",
    "    n_sweeps_array = np.arange(len(domain_magnetizations[0, :]))    # Array de sweeps\n",
    "\n",
    "    for i in range(len(n_sweeps_array)):\n",
    "        n_sweeps_array[i] = n_sweeps_array[i]*thin\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(n_sweeps_array, domain_magnetizations[0, :], linestyle='-', label='Dominio superior')\n",
    "    plt.plot(n_sweeps_array, domain_magnetizations[1, :], linestyle='-', label='Dominio inferior')\n",
    "    plt.xlabel('Sweep')\n",
    "    plt.ylabel('Magnetización')\n",
    "    plt.title('Magnetización del dominio superior e inferior (Kawasaki)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(destino, 'domain_magnetization.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # ─── Densidad de part en dir y ────────────────────\n",
    "\n",
    "    density = calcular_densidad_party(frames)\n",
    "    y_array = np.arange(len(density))                           # Eje y de la matriz de configuración\n",
    "    for i in range(len(y_array)):\n",
    "        y_array[i] = y_array[i]*thin\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(density, y_array, linestyle='-')\n",
    "    plt.xlabel('Mean Particle Density')\n",
    "    plt.ylabel('y axis')\n",
    "    plt.title('Densidad de media partículas en la direccion y')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(destino, 'DensityAlongYAxis.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Creamos el array de energía media por partícula \n",
    "    mean_energy_per_particle = energies[-1] / (H*W*0.5*(magnetizations[-1] + 1))  # Energía media por \"partícula\"\n",
    "\n",
    "    return {'density': density, 'mean_energy_per_particle': mean_energy_per_particle, 'energy': energies, 'domain_magnetization': domain_magnetizations}                                        \n",
    "\n",
    "# Devolvemos el array de observables (si hay más de uno, puedo usar return {'density': density, 'energy': energies, 'magnetization': magnetizations} para devolver un diccionario con todos los observables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e988e",
   "metadata": {},
   "source": [
    "### Celda 6:\n",
    "En esta celda se define la función _run_monte_carlo(...)_, que ejecuta el barrido Monte Carlo completo y almacena las configuraciones en un archivo HDF5, lo que nos permite almacenar mucha información de forma muy eficiente. Sus pasos son:\n",
    "\n",
    "1. Inicialización:\n",
    "   - Llama a _init_config(...)_ para generar y guardar la configuración inicial en PNG.  \n",
    "   - Calcula el número de sweeps guardados:  \n",
    "     $$\n",
    "       \\text{saved\\_sweeps} = \\lfloor \\text{n}\\_\\text{sweeps} / \\text{thin} \\rfloor + 1\n",
    "     $$  \n",
    "   - Define $ \\Beta = 1/T $.  \n",
    "\n",
    "2. Creación del archivo HDF5:\n",
    "   - Abre (o crea) _configs.h5_ en modo escritura.  \n",
    "   - Crea el dataset _configs_ con forma _(saved_sweeps, L, L)_ y tipo _i1_ (espines ±1).  \n",
    "   - Aplica compresión gzip (_compression_opts=4_) y chunks _(1, L, L)_.  \n",
    "   - Guarda metadatos: _J_, _T_, _L_, _saved_sweeps_, _thin_.  \n",
    "   - Escribe la configuración inicial en _dataset[0]_.  \n",
    "\n",
    "3. Primer sweep:\n",
    "   - Aplica un sweep de Kawasaki (con o sin fronteras, según _Boundary_conditions_) antes del bucle principal.  \n",
    "\n",
    "4. Bucle principal de sweeps:\n",
    "   - Itera _sweep_ de 1 a _n_sweeps_, mostrando barra de progreso _tqdm_.  \n",
    "   - Cada sweep:  \n",
    "     - Ejecuta un sweep de Kawasaki.  \n",
    "     - Si _sweep % thin == 0_, guarda _config_ en _dataset[i]_.  \n",
    "     - Si ya se ha guardado al menos el 10% de _saved_sweeps_ *y* no es asimétrica,  \n",
    "       se comprueba la pendiente de la tasa de aceptación en una ventana de datos:  \n",
    "       - Calcula la tasa de aceptación en ventanas crecientes.  \n",
    "       - Si la pendiente es menor que _threshold_ o la tasa crece >20%, detiene la simulación anticipadamente.  \n",
    "\n",
    "5. Ajuste y cierre:\n",
    "   - Redimensiona el dataset a _(i+1, L, L)_ para ajustar el número real de sweeps guardados.  \n",
    "   - Actualiza el atributo _saved_sweeps_.  \n",
    "   - Mide y muestra el tiempo total de simulación.  \n",
    "\n",
    "6. Post-procesado:\n",
    "   - Llama a _plot_observables(destino, J, density)_ para graficar los observables y devuelve sus resultados.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94e3be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6: Bucle Monte Carlo y recolección de datos con HDF5\n",
    "\n",
    "def run_monte_carlo(L, J, T, n_sweeps, thin, destino, Boundary_conditions, density, max_window, threshold, Asimmetric):\n",
    "\n",
    "    # ─── Inicialización de la simulación ────────────────────────────────\n",
    "    \n",
    "    config = init_config(os.path.join(destino, \"init_config.png\"), L, density, Boundary_conditions, Asimmetric)  # Guardar configuración inicial\n",
    "    saved_sweeps = n_sweeps // thin + 1 # Número de sweeps guardados\n",
    "    # Calcular Beta\n",
    "    Beta = 1.0 / T\n",
    "\n",
    "    # Parámetros de guardado\n",
    "\n",
    "    with h5py.File(os.path.join(destino, 'configs.h5'), 'w') as f:\n",
    "        # Dataset para las configuraciones: snapshots × L × L, dtype int8\n",
    "        dataset = f.create_dataset(\n",
    "            'configs',                      # 1. Nombre del dataset dentro del archivo HDF5\n",
    "            shape=(saved_sweeps, L, L),     # 2. Dimensiones: n_saved muestras de matrices L×L     \n",
    "            maxshape=(None, L, L),          # 3. Dimensión máxima: puede crecer indefinidamente en el eje de muestras\n",
    "            dtype='i1',                     # 4. Tipo de dato: int1 (espines ±1)\n",
    "            compression='gzip',             # 5. Compresión: algoritmo gzip\n",
    "            compression_opts=4,             # 6. Nivel de compresión (1=rápido/menos compacto … 9=lento/máximo)\n",
    "            chunks=(1, L, L),               # 7. Fragmentación (“chunking”): cada bloque es una matriz L×L\n",
    "        )\n",
    "        # Metadatos\n",
    "        f.attrs['J'] = J\n",
    "        f.attrs['T'] = T\n",
    "        f.attrs['L'] = L\n",
    "        f.attrs['saved_sweeps'] = saved_sweeps\n",
    "        f.attrs['thin'] = thin\n",
    "\n",
    "        # Guardar configuración inicial ds[0]\n",
    "        dataset[0, :, :] = config\n",
    "        if Boundary_conditions:\n",
    "            sweep_kawasaki_boundary(config, L, J, Beta)\n",
    "        else:\n",
    "            sweep_kawasaki_non_boundary(config, L, J, Beta)\n",
    "\n",
    "        # Barrido Monte Carlo\n",
    "        i=0\n",
    "        start_time = time.time()\n",
    "        for sweep in tqdm(range(1, n_sweeps + 1), desc='MC Sweeps'):  # Esto es una simple barra de progreso, nada más\n",
    "            # Ahora podemos barrer la red para elegir el par de espines a intercambiar.\n",
    "            if Boundary_conditions:\n",
    "                sweep_kawasaki_boundary(config, L, J, Beta)\n",
    "            else:\n",
    "                sweep_kawasaki_non_boundary(config, L, J, Beta)\n",
    "\n",
    "            # Almacenar las configuraciones \n",
    "            \n",
    "            if sweep % thin == 0:  # Guardar cada thin sweeps\n",
    "                i = sweep // thin\n",
    "                dataset[i, :, :] = config\n",
    "                # Ahora creamos la condición de parada, que será cuando la pendiente de la tasa de aceptación sea menor que un umbral (se establice)\n",
    "                if (i >= int(0.1 * saved_sweeps)) and not Asimmetric:  # Si hemos guardado al menos el 5% de los sweeps y la config es aleatoria\n",
    "                    # Calcular la tasa de aceptación y detener si es menor que el umbral\n",
    "                    window = min(max_window, i//4)  # Ventana de datos para la tasa de aceptación (entre el 25% de los sweeps guardados y el máximo establecido)\n",
    "                    if window >= 3:   \n",
    "                        dataset_window = dataset[:2, :, :]\n",
    "                        acceptance_array = calculate_acceptance(dataset_window)\n",
    "                        initial_acceptance = acceptance_array[-1]  # Último valor de aceptación (debería ser el 0)\n",
    "                        dataset_window = dataset[i-2:i, :, :]\n",
    "                        acceptance_array = calculate_acceptance(dataset_window)\n",
    "                        current_acceptance = acceptance_array[-1]  # Último valor de aceptación (debería ser el 0)\n",
    "                        dataset_window = dataset[i-window:i, :, :]\n",
    "                        acceptance_array = calculate_acceptance(dataset_window)\n",
    "                        if acceptance_slope(acceptance_array, threshold):\n",
    "                            print(f\"Simulación detenida en sweep {sweep} por tasa de aceptación.\")\n",
    "                            break\n",
    "                        # Esto lo añado si quiero que la simulación se detenga si no va a converger\n",
    "                        elif current_acceptance >= initial_acceptance*1.2:  # Si la tasa de aceptación ha aumentado un 20% respecto a la inicial\n",
    "                            print(f\"Simulación detenida en sweep {sweep} por tasa de aceptación creciente.\")\n",
    "                            break\n",
    "            if not Asimmetric:    \n",
    "                if sweep == n_sweeps:  # Si hemos llegado al último sweep, escribimos el último valor de pendiente de aceptación\n",
    "                    x = np.arange(acceptance_array.size)\n",
    "                    print(\"\\n\")\n",
    "                    print(abs(linear_regression_slope(x, acceptance_array)))\n",
    "            \n",
    "\n",
    "        dataset.resize((i + 1, L, L))  # Ajustar tamaño final del dataset\n",
    "        f.attrs['saved_sweeps'] = i + 1\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Simulación completada en {end_time - start_time:.2f} s\")\n",
    "\n",
    "    # Graficar, guardar y devolver los observables\n",
    "    return plot_observables(destino, J, density)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e73fe7",
   "metadata": {},
   "source": [
    "### Celda 7:\n",
    "\n",
    "Esta celda fue generada con ChatGPT por completo, por lo que no puedo desarrollar en profundidad lo que hace cada sección. Sin embargo, intentado comprende algo de lo que hace puedo dar una descripción general de proceso:\n",
    "\n",
    "- En primer lugar se extran los datos necesarios del archivo _.h5_. \n",
    "- Una vez hecho eso se calculan los parámetros del vídeo: fps, resolución, ...\n",
    "- Luego se intenta detectar el NVENC que es un codificador de NVIDIA que nos va a permitir acelerar por GPU el video, aunque como ya veremos no nos va a ser de demsasiada ayuda.\n",
    "- Por último, en función de si ha encontrado el NVENC o no, establece unas opciones de vídeo y envía los frames y codifica el vídeo, para después descargarlo en la carpeta donde se le indique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "063336c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7: Pipeline GPU-bound con NVENC a partir de HDF5\n",
    "\n",
    "def generate_video_from_hdf5(HDF5_FILE, DATASET, FILE_OUT, GPU_ID, INTERVAL, TARGET_size, MIN_SIDE, destino):\n",
    "\n",
    "    # 1) Cargar datos -------------------------------------------------------------------------\n",
    "    with h5py.File(os.path.join(destino, HDF5_FILE), 'r') as f:\n",
    "        frames = f[DATASET][::]\n",
    "    nframes, h0, w0 = frames.shape\n",
    "    fps = 1000.0 / INTERVAL\n",
    "    print(f\"🎞️  Generando vídeo: {nframes} frames @ {fps:.1f} fps\")\n",
    "\n",
    "    # 2) Calcular resolución de salida --------------------------------------------------------\n",
    "    w_out, h_out = w0, h0\n",
    "    if TARGET_size:\n",
    "        w_out = h_out = TARGET_size\n",
    "\n",
    "    # Asegurar mínimo NVENC\n",
    "    if min(w_out, h_out) < MIN_SIDE:\n",
    "        factor = math.ceil(MIN_SIDE / min(w_out, h_out))\n",
    "        w_out *= factor\n",
    "        h_out *= factor\n",
    "\n",
    "    # Redondear a par\n",
    "    w_out = (w_out // 2) * 2\n",
    "    h_out = (h_out // 2) * 2\n",
    "    if (w_out, h_out) != (w0, h0):\n",
    "        print(f\"↕️  Escalado de resolución: {w0}×{h0} → {w_out}×{h_out}\")\n",
    "    vf_filter = [\"-vf\", f\"scale={w_out}:{h_out}:flags=neighbor\"] if (w_out, h_out) != (w0, h0) else []\n",
    "\n",
    "    # 3) Detectar NVENC -----------------------------------------------------------------------\n",
    "    encoders = subprocess.run(\n",
    "        [\"ffmpeg\", \"-hide_banner\", \"-encoders\"],\n",
    "        capture_output=True, text=True\n",
    "    ).stdout\n",
    "    if \"h264_nvenc\" in encoders:\n",
    "        print(\"✅ NVENC (GPU) activado\")\n",
    "        video_opts = [\n",
    "            \"-c:v\", \"h264_nvenc\", \"-gpu\", str(GPU_ID),\n",
    "            \"-preset\", \"p1\", \"-profile:v\", \"high444p\", \"-pix_fmt\", \"yuv444p\"\n",
    "        ]\n",
    "    else:\n",
    "        print(\"⚠️ Usando codificación por CPU (libx264)\")\n",
    "        video_opts = [\"-c:v\", \"libx264\", \"-preset\", \"veryslow\", \"-crf\", \"0\", \"-pix_fmt\", \"yuv420p\"]\n",
    "\n",
    "    # 4) Comando FFmpeg -----------------------------------------------------------------------\n",
    "    cmd = (\n",
    "        [\"ffmpeg\", \"-y\",\n",
    "        \"-f\", \"rawvideo\", \"-pix_fmt\", \"rgb24\",\n",
    "        \"-s\", f\"{w0}x{h0}\", \"-r\", str(fps), \"-i\", \"-\",\n",
    "        \"-progress\", \"pipe:1\", \"-loglevel\", \"error\"]\n",
    "        + vf_filter + video_opts + [f\"{os.path.join(destino, FILE_OUT)}.mp4\"]\n",
    "    )\n",
    "\n",
    "    # 5) Lanzar FFmpeg ------------------------------------------------------------------------\n",
    "    proc = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdin = subprocess.PIPE,\n",
    "        stdout = subprocess.PIPE,\n",
    "        stderr = subprocess.PIPE,\n",
    "        bufsize = 0\n",
    "    )\n",
    "\n",
    "    # 6) Barra de codificación ---------------------------------------------------------------\n",
    "    pbar_enc = tqdm(total=nframes, desc=\"🛠️ Codificando\", unit=\"frame\")\n",
    "    def _watch():\n",
    "        re_time = re.compile(rb\"out_time_ms=(\\d+)\")\n",
    "        re_fr   = re.compile(rb\"frame=(\\d+)\")\n",
    "        while True:\n",
    "            line = proc.stdout.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            m = re_fr.search(line) or re_time.search(line)\n",
    "            if m:\n",
    "                val = int(m.group(1))\n",
    "                done = val if b\"frame\" in line else min(nframes, int(round(val * fps / 1000)))\n",
    "                pbar_enc.n = done\n",
    "                pbar_enc.refresh()\n",
    "\n",
    "    threading.Thread(target=_watch, daemon=True).start()\n",
    "\n",
    "    # 7) Enviar frames ------------------------------------------------------------------------\n",
    "    with tqdm(total=nframes, desc=\"📤 Enviando frames\", unit=\"frame\") as pbar_in:\n",
    "        for frame in frames:\n",
    "            # Convertir de Ising (-1,+1) a [0,255] y a RGB\n",
    "            rgb = np.repeat(((frame + 1) * 127.5).astype(np.uint8)[..., None], 3, axis=2)\n",
    "            proc.stdin.write(rgb.tobytes())\n",
    "            pbar_in.update(1)\n",
    "\n",
    "    proc.stdin.close()\n",
    "    proc.wait()\n",
    "    pbar_enc.n = nframes\n",
    "    pbar_enc.refresh()\n",
    "    pbar_enc.close()\n",
    "\n",
    "    print(f\"🎉 Vídeo generado: {os.path.join(destino, FILE_OUT)}.mp4 ({w_out}×{h_out})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa667cd",
   "metadata": {},
   "source": [
    "### Celda 8:\n",
    "\n",
    "La función _run_whole_simulation(...)_ orquesta toda la simulación para un conjunto de parámetros dados y automatiza:\n",
    "\n",
    "1. Configuración de paralelismo:\n",
    "   - Llama a _establecer_numero_hilos(threads_percentage)_ para ajustar el número de hilos de Numba según el porcentaje solicitado.\n",
    "\n",
    "2. Creación de carpeta de resultados única:  \n",
    "   - Asegura que exista la carpeta base _carpeta_.  \n",
    "   - Construye _destino_base = carpeta/L{L}_J{J}_T{T:.2f}_sweeps{n_sweeps}_threads{threads_percentage}_.  \n",
    "   - Si ya existe, añade sufijos __({counter})_ hasta encontrar un nombre libre.  \n",
    "   - Crea finalmente la carpeta _destino_.\n",
    "\n",
    "3. Ejecución de la simulación Monte Carlo: \n",
    "   - Llama a  \n",
    "     ```\n",
    "     observables = run_monte_carlo(\n",
    "       L, J, T, n_sweeps, thin, destino,\n",
    "       Boundary_conditions, density,\n",
    "       max_window, threshold, Asimmetric\n",
    "     )\n",
    "     ```  \n",
    "     que devuelve un diccionario con los observables calculados.\n",
    "\n",
    "4. Generación de vídeo:  \n",
    "   - Llama a  \n",
    "     ```\n",
    "     generate_video_from_hdf5(\n",
    "       HDF5_FILE, DATASET, FILE_OUT, GPU_ID,\n",
    "       INTERVAL, TARGET_size, MIN_SIDE, destino\n",
    "     )\n",
    "     ```  \n",
    "     para convertir las configuraciones HDF5 en un archivo MP4 usando NVENC o libx264.\n",
    "\n",
    "5. Retorno de resultados: \n",
    "   - Devuelve el diccionario _observables_ con los arrays de densidad, energía media, magnetización por dominios, etc., listo para posteriores análisis o graficado.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34a1b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8: Función de simulación completa (wrapper)\n",
    "\n",
    "def run_whole_simulation(L, J, T, n_sweeps, threads_percentage, thin, Boundary_conditions, density, carpeta, max_window, threshold, Asimmetric, HDF5_FILE, DATASET, FILE_OUT, GPU_ID, INTERVAL, TARGET_size, MIN_SIDE):\n",
    "\n",
    "    # ─── Establecer el número de hilos a usar ──────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "    establecer_numero_hilos(threads_percentage)  \n",
    "\n",
    "    # ─── Definición nombre carpeta ─────────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "                                                                                       # La idea en esta parte es simple, queremos crear\n",
    "    if not os.path.exists(carpeta):                                                                         # una carpeta de resultados siempre que hagamos una\n",
    "        os.makedirs(carpeta)                                                                                # simulación, la hayamos hecho antes o no, y que sea única.\n",
    "    destino_base = os.path.join(carpeta, f\"L{L}_J{J}_T{T:.2f}_sweeps{n_sweeps}_threads{threads_percentage}\")    # Con este fin, hemos hecho un pequeño bucle que comprueba\n",
    "    destino = destino_base                                                                                  # si la carpeta ya existe, y si es así, le añade un número \n",
    "    counter = 1                                                                                             # al final de la carpeta, para que sea única.\n",
    "    while os.path.exists(destino):\n",
    "        destino = f\"{destino_base}_({counter})\" \n",
    "        counter += 1\n",
    "    os.makedirs(destino)  # Crear una carpeta de destino única\n",
    "\n",
    "    # Ahora ejecutamos el programa completo\n",
    "\n",
    "    observables = run_monte_carlo(L, J, T, n_sweeps, thin, destino, Boundary_conditions, density, max_window, threshold, Asimmetric)\n",
    "\n",
    "    generate_video_from_hdf5(HDF5_FILE, DATASET, FILE_OUT, GPU_ID, INTERVAL, TARGET_size, MIN_SIDE, destino)\n",
    "\n",
    "    return observables  # Devolver los observables calculados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03bf3f",
   "metadata": {},
   "source": [
    "### Celda 9:\n",
    "\n",
    "En esta celda se definen varias funciones que generan y guardan gráficas de los distintos observables calculados en la simulación:\n",
    "\n",
    "- _plot_density_y(dict_densities, T_init, T_step, L_init, L_step, destino)_:\n",
    "  1. Crea la carpeta _Densities_ dentro de _destino_ si no existe.  \n",
    "  2. Para cada tamaño de red $L = L_{\\text{init}} + j\\,L_{\\text{step}}$:  \n",
    "     - Extrae el array _density_y_ de forma $(n_{\\text{Temp}}, L)$ del diccionario.  \n",
    "     - Calcula el eje vertical $y = 0, 1, \\dots, L-1$ y los valores de temperatura $T_i = T_{\\text{init}} + i\\,T_{\\text{step}}\\quad (i=0,\\dots,n_{\\text{Temp}}-1).$  \n",
    "     - Dibuja densidad vs. posición \\(y\\) para cada temperatura y guarda _DensityAlongYAxis_Temperature_L{L}.png_.  \n",
    "\n",
    "- _plot_mean_energy_per_particle(mean_energies_per_particle, T_init, T_step, L_init, L_step, destino)_:  \n",
    "  1. Para cada tamaño de red $L_j = L_{\\text{init}} + j\\,L_{\\text{step}}$:  \n",
    "     - Extrae la columna correspondiente de _mean_energies_per_particle_ (forma $(n_{\\text{Temp}}, n_Ls)$).  \n",
    "     - Calcula los valores de temperatura $T_i$ como arriba.  \n",
    "     - Dibuja energía media por partícula vs. $T$ y guarda _MeanEnergyPerParticle_Temperature.png_.  \n",
    "\n",
    "- _plot_specific_heat(SH, T_init, T_step, L_init, L_step, destino)_:\n",
    "  1. Para cada tamaño de red $L_j$:  \n",
    "     - Extrae la columna de _SH_ (capacidad calorífica).  \n",
    "     - Dibuja $C_N(T)$ vs. $T$ y guarda _SpecificHeat_Temperature.png_.  \n",
    "\n",
    "- _plot_susceptibility(MS, T_init, T_step, L_init, L_step, destino)_:\n",
    "  1. Para cada $L_j$:  \n",
    "     - Extrae la columna de _MS_ (susceptibilidad magnética).  \n",
    "     - Dibuja $\\chi_N(T)$ vs. $T$ y guarda _Susceptibility_Temperature.png_.  \n",
    "\n",
    "- _plot_Tcrit_L(T_crit_L, L_init, L_step, destino, filename)_\n",
    "  1. Calcula valores de $L_j$ y recibe el vector _T_crit_L_ con los picos de $C_N$ o $\\chi_N$.  \n",
    "  2. Dibuja temperatura crítica $T_c(L)$ vs. $L$ y guarda el archivo _filename_.  \n",
    "\n",
    "- _plot_magnetizations_vs_temp(magnetizations_vs_temp, T_init, T_step, L_init, L_step, destino)_:  \n",
    "  1. Crea la carpeta _Magnetizations_vs_temp_ en _destino_ si no existe.  \n",
    "  2. Para cada $L_j$:  \n",
    "     - Extrae los arrays de magnetización del dominio superior e inferior (dimensión $(n_{\\text{Temp}},2)$).  \n",
    "     - Dibuja ambas curvas vs. $T_i$ y guarda _L_{L_j}.png_.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efa9402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 9: Funciones para graficar observables\n",
    "\n",
    "def plot_density_y(dict_densities, T_init, T_step, L_init, L_step, destino):\n",
    "\n",
    "    if not os.path.exists(os.path.join(destino, \"Densities\")):\n",
    "        carpeta_densities = os.path.join(destino, \"Densities\")\n",
    "        os.makedirs(carpeta_densities)\n",
    "\n",
    "    n_Ls = len(dict_densities)  # Número de tamaños de red\n",
    "\n",
    "    for j in range(n_Ls):\n",
    "        density_y = dict_densities[f'Density_L{L_init + j * L_step}']   # np.ndarray (n_Temp, L)\n",
    "        n_Temp, L = density_y.shape                                     # n_Temp = número de temperaturas, L = tamaño de la red\n",
    "        y_axis = np.arange(L)                                           # Eje y de la matriz de configuración\n",
    "        T_values = T_init + np.arange(n_Temp)*T_step \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for i in range(n_Temp):\n",
    "            plt.plot(density_y[i,:], y_axis, linestyle='-', label=f'T={T_values[i]:.2f}')\n",
    "        plt.xlabel('Densidad de partículas')\n",
    "        plt.ylabel('y axis')\n",
    "        plt.title(f'Densidad de partículas a lo largo de la dirección y para {n_Temp} temperaturas y L={L}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(carpeta_densities, f'DensityAlongYAxis_Temperature_L{L}.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "def plot_mean_energy_per_particle(mean_energies_per_particle, T_init, T_step, L_init, L_step, destino):\n",
    "\n",
    "    n_Temp, n_Ls = mean_energies_per_particle.shape\n",
    "    T_values = T_init + np.arange(n_Temp)*T_step\n",
    "    L_values = L_init + np.arange(n_Ls)*L_step\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(n_Ls):\n",
    "        plt.plot(T_values, mean_energies_per_particle[:, i], label= f'L={L_values[i]}', linestyle='-')\n",
    "    plt.xlabel('Temperatura (T)')\n",
    "    plt.ylabel('Energía media por partícula')\n",
    "    plt.title('Energía media por partícula por temperatura a diferentes tamaños de red')\n",
    "    plt.legend()  \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(destino, 'MeanEnergyPerParticle_Temperature.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_specific_heat(SH, T_init, T_step, L_init, L_step, destino):\n",
    "\n",
    "    n_Temp, n_Ls = SH.shape\n",
    "    T_values = T_init + np.arange(n_Temp)*T_step\n",
    "    L_values = L_init + np.arange(n_Ls)*L_step    \n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(n_Ls):\n",
    "        plt.plot(T_values, SH[:, i], label= f'L={L_values[i]}', linestyle='-')\n",
    "    plt.xlabel('Temperatura (T)')\n",
    "    plt.ylabel('Calor específico')\n",
    "    plt.title('Calor específico por temperatura a diferentes tamaños de red')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(destino, 'SpecificHeat_Temperature.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_susceptibility(MS, T_init, T_step, L_init, L_step, destino):\n",
    "    \"\"\"\n",
    "    Plotea la susceptibilidad magnética en función de la temperatura.\n",
    "    \"\"\"\n",
    "    n_Temp, n_Ls = MS.shape\n",
    "    T_values = T_init + np.arange(n_Temp)*T_step\n",
    "    L_values = L_init + np.arange(n_Ls)*L_step\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(n_Ls):\n",
    "        plt.plot(T_values, MS[:, i], label= f'L={L_values[i]}', linestyle='-')\n",
    "    plt.xlabel('Temperatura (T)')\n",
    "    plt.ylabel('Susceptibilidad magnética')\n",
    "    plt.title('Susceptibilidad magnética por temperatura a diferentes tamaños de red')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(destino, 'Susceptibility_Temperature.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_Tcrit_L(T_crit_L, L_init, L_step, destino, filename):\n",
    "    \"\"\"\n",
    "    Plotea la temperatura crítica en función del tamaño de la red L.\n",
    "    \"\"\"\n",
    "    L_values = L_init + np.arange(T_crit_L.size)*L_step\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(L_values, T_crit_L, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Tamaño de la red (L)')\n",
    "    plt.ylabel('Temperatura crítica (T_c)')\n",
    "    plt.title('Temperatura crítica en función del tamaño de la red')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(destino, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_magnetizations_vs_temp(magnetizations_vs_temp: np.ndarray, T_init, T_step, L_init, L_step, destino):\n",
    "\n",
    "    n_Temp, n_Ls, domain = magnetizations_vs_temp.shape\n",
    "    T_values = T_init + np.arange(n_Temp)*T_step\n",
    "    L_values = L_init + np.arange(n_Ls)*L_step \n",
    "\n",
    "    if not os.path.exists(os.path.join(destino, \"Magnetizations_vs_temp\")):\n",
    "        carpeta_magnetizations = os.path.join(destino, \"Magnetizations_vs_temp\")\n",
    "        os.makedirs(carpeta_magnetizations)\n",
    "\n",
    "    for i in range(n_Ls):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(T_values, magnetizations_vs_temp[:, i, 0], linestyle='-', color='b')\n",
    "        plt.plot(T_values, magnetizations_vs_temp[:, i, 1], linestyle='-', color='r')\n",
    "        plt.xlabel('Temperatura (T)')\n",
    "        plt.ylabel('Energía media por partícula')\n",
    "        plt.title('Energía media por partícula por temperatura a diferentes tamaños de red')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(carpeta_magnetizations, f'L_{L_values[i]}.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd97e73e",
   "metadata": {},
   "source": [
    "### Celda 10:\n",
    "\n",
    "Esta celda define la función _main()_ que coordina múltiples simulaciones variando temperatura y tamaño de red, y genera todos los gráficos finales.\n",
    "\n",
    "1. Parámetros base del modelo:\n",
    "   - _L_, _J_, _T_, _n_sweeps_, _density_, _threads_percentage_, _thin_, _Boundary_conditions_, _max_window_, _threshold_, _Asimmetric_.  \n",
    "   - Determinan la red, dinámica, convergencia y condiciones de frontera.\n",
    "\n",
    "2. Parámetros para vídeo:\n",
    "   - _HDF5_FILE_, _DATASET_, _FILE_OUT_, _GPU_ID_, _INTERVAL_, _TARGET_size_, _MIN_SIDE_.\n",
    "\n",
    "3. Preparación de carpeta de resultados:\n",
    "   - Crea _results/Simulacion_Multiple(X)_ de forma única.\n",
    "\n",
    "4. Rangos de temperatura y tamaño:\n",
    "   - Temperaturas: desde _T_init_ hasta _T_max_ con paso _T_step_.  \n",
    "   - Tamaños de red: desde _L_init_ hasta _L_max_ con paso _L_step_.  \n",
    "   - Calcula _n_temps_ y _n_Ls_.\n",
    "\n",
    "5. Inicialización de los arrays donde van a ir los observables:\n",
    "   - _mean_energies_per_particle_, _SH_, _MS_, _magnetization_vs_temp_, _dict_densities_.\n",
    "\n",
    "6. Bucle de simulaciones:  \n",
    "   - Recorre todos los tamaños de red, y dentro de cada uno de ellos, todas las temperaturas.\n",
    "   - En cada iteración recoje todos los observables y los almacena. \n",
    "   \n",
    "7. Almacenamiento observables\n",
    "   - Se genera una carpeta donde se almacenarán todos los observables.\n",
    "   - Define un último observable _T_crit_L_SH_ y _T_crit_L_MS_, la temperatura crítica con el tamaño de la red.\n",
    "   - Plotea todos los observables, y los almacena en la carpeta que ha creado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7003daf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando 16 hilos de 16 disponibles (100%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Sweeps: 100%|██████████| 10000/10000 [00:00<00:00, 34478.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulación completada en 0.29 s\n",
      "🎞️  Generando vídeo: 1001 frames @ 20.0 fps\n",
      "↕️  Escalado de resolución: 16×16 → 1440×1440\n",
      "✅ NVENC (GPU) activado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Enviando frames: 100%|██████████| 1001/1001 [00:01<00:00, 568.38frame/s]\n",
      "🛠️ Codificando: 100%|██████████| 1001/1001 [00:01<00:00, 531.52frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Vídeo generado: results\\Simulacion_Multiple_(1)\\L16_J1.0_T2.00_sweeps10000_threads100\\simulacion.mp4 (1440×1440)\n",
      "Usando 16 hilos de 16 disponibles (100%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Sweeps: 100%|██████████| 10000/10000 [00:00<00:00, 33137.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulación completada en 0.30 s\n",
      "🎞️  Generando vídeo: 1001 frames @ 20.0 fps\n",
      "↕️  Escalado de resolución: 16×16 → 1440×1440\n",
      "✅ NVENC (GPU) activado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Enviando frames: 100%|██████████| 1001/1001 [00:01<00:00, 572.55frame/s]\n",
      "🛠️ Codificando: 100%|██████████| 1001/1001 [00:01<00:00, 538.99frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Vídeo generado: results\\Simulacion_Multiple_(1)\\L16_J1.0_T2.12_sweeps10000_threads100\\simulacion.mp4 (1440×1440)\n",
      "Usando 16 hilos de 16 disponibles (100%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Sweeps: 100%|██████████| 10000/10000 [00:00<00:00, 33362.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulación completada en 0.30 s\n",
      "🎞️  Generando vídeo: 1001 frames @ 20.0 fps\n",
      "↕️  Escalado de resolución: 16×16 → 1440×1440\n",
      "✅ NVENC (GPU) activado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Enviando frames: 100%|██████████| 1001/1001 [00:01<00:00, 545.52frame/s]\n",
      "🛠️ Codificando: 100%|██████████| 1001/1001 [00:01<00:00, 513.47frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Vídeo generado: results\\Simulacion_Multiple_(1)\\L16_J1.0_T2.25_sweeps10000_threads100\\simulacion.mp4 (1440×1440)\n",
      "Usando 16 hilos de 16 disponibles (100%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Sweeps: 100%|██████████| 10000/10000 [00:00<00:00, 31019.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulación completada en 0.32 s\n",
      "🎞️  Generando vídeo: 1001 frames @ 20.0 fps\n",
      "↕️  Escalado de resolución: 16×16 → 1440×1440\n",
      "✅ NVENC (GPU) activado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Enviando frames: 100%|██████████| 1001/1001 [00:01<00:00, 577.40frame/s]\n",
      "🛠️ Codificando: 100%|██████████| 1001/1001 [00:01<00:00, 541.22frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Vídeo generado: results\\Simulacion_Multiple_(1)\\L16_J1.0_T2.38_sweeps10000_threads100\\simulacion.mp4 (1440×1440)\n",
      "Usando 16 hilos de 16 disponibles (100%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Sweeps: 100%|██████████| 10000/10000 [00:00<00:00, 32792.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulación completada en 0.31 s\n",
      "🎞️  Generando vídeo: 1001 frames @ 20.0 fps\n",
      "↕️  Escalado de resolución: 16×16 → 1440×1440\n",
      "✅ NVENC (GPU) activado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Enviando frames: 100%|██████████| 1001/1001 [00:01<00:00, 572.75frame/s]\n",
      "🛠️ Codificando: 100%|██████████| 1001/1001 [00:01<00:00, 538.63frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Vídeo generado: results\\Simulacion_Multiple_(1)\\L16_J1.0_T2.50_sweeps10000_threads100\\simulacion.mp4 (1440×1440)\n",
      "Usando 16 hilos de 16 disponibles (100%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Sweeps: 100%|██████████| 10000/10000 [00:00<00:00, 19186.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulación completada en 0.52 s\n",
      "🎞️  Generando vídeo: 1001 frames @ 20.0 fps\n",
      "↕️  Escalado de resolución: 20×20 → 1440×1440\n",
      "✅ NVENC (GPU) activado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Enviando frames: 100%|██████████| 1001/1001 [00:01<00:00, 567.74frame/s]\n",
      "🛠️ Codificando: 100%|██████████| 1001/1001 [00:01<00:00, 531.29frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Vídeo generado: results\\Simulacion_Multiple_(1)\\L20_J1.0_T2.00_sweeps10000_threads100\\simulacion.mp4 (1440×1440)\n",
      "Usando 16 hilos de 16 disponibles (100%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Sweeps: 100%|██████████| 10000/10000 [00:00<00:00, 19363.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulación completada en 0.52 s\n",
      "🎞️  Generando vídeo: 1001 frames @ 20.0 fps\n",
      "↕️  Escalado de resolución: 20×20 → 1440×1440\n",
      "✅ NVENC (GPU) activado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Enviando frames: 100%|██████████| 1001/1001 [00:01<00:00, 565.80frame/s]\n",
      "🛠️ Codificando: 100%|██████████| 1001/1001 [00:01<00:00, 531.46frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Vídeo generado: results\\Simulacion_Multiple_(1)\\L20_J1.0_T2.12_sweeps10000_threads100\\simulacion.mp4 (1440×1440)\n",
      "Usando 16 hilos de 16 disponibles (100%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Sweeps: 100%|██████████| 10000/10000 [00:00<00:00, 18860.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulación completada en 0.53 s\n",
      "🎞️  Generando vídeo: 1001 frames @ 20.0 fps\n",
      "↕️  Escalado de resolución: 20×20 → 1440×1440\n",
      "✅ NVENC (GPU) activado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Enviando frames: 100%|██████████| 1001/1001 [00:01<00:00, 567.99frame/s]\n",
      "🛠️ Codificando: 100%|██████████| 1001/1001 [00:01<00:00, 533.88frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Vídeo generado: results\\Simulacion_Multiple_(1)\\L20_J1.0_T2.25_sweeps10000_threads100\\simulacion.mp4 (1440×1440)\n",
      "Usando 16 hilos de 16 disponibles (100%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Sweeps: 100%|██████████| 10000/10000 [00:00<00:00, 20001.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulación completada en 0.50 s\n",
      "🎞️  Generando vídeo: 1001 frames @ 20.0 fps\n",
      "↕️  Escalado de resolución: 20×20 → 1440×1440\n",
      "✅ NVENC (GPU) activado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Enviando frames: 100%|██████████| 1001/1001 [00:01<00:00, 566.28frame/s]\n",
      "🛠️ Codificando: 100%|██████████| 1001/1001 [00:01<00:00, 532.36frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Vídeo generado: results\\Simulacion_Multiple_(1)\\L20_J1.0_T2.38_sweeps10000_threads100\\simulacion.mp4 (1440×1440)\n",
      "Usando 16 hilos de 16 disponibles (100%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC Sweeps: 100%|██████████| 10000/10000 [00:00<00:00, 18016.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulación completada en 0.56 s\n",
      "🎞️  Generando vídeo: 1001 frames @ 20.0 fps\n",
      "↕️  Escalado de resolución: 20×20 → 1440×1440\n",
      "✅ NVENC (GPU) activado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Enviando frames: 100%|██████████| 1001/1001 [00:01<00:00, 533.57frame/s]\n",
      "🛠️ Codificando: 100%|██████████| 1001/1001 [00:01<00:00, 505.34frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Vídeo generado: results\\Simulacion_Multiple_(1)\\L20_J1.0_T2.50_sweeps10000_threads100\\simulacion.mp4 (1440×1440)\n",
      "Simulación completada en 35.69 s\n"
     ]
    }
   ],
   "source": [
    "# Celda 10: Ejecución del programa completo\n",
    "\n",
    "def main():\n",
    "\n",
    "    # ─── Parámetros base del modelo ────────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "    L                   = 16                        # (int) Tamaño de la red (LxL)\n",
    "    J                   = 1.0                       # (float) Constante de interacción (J > 0 para ferromagnetismo)\n",
    "    T                   = 1.0                       # (float) Temperatura del modelo de Ising 2D\n",
    "    n_sweeps            = 10000                     # (int) Número de sweeps (barridos) a realizar\n",
    "    density             = 0.75                       # (float) Densidad de espines +1\n",
    "    threads_percentage  = 100                       # (int) Porcentaje de hilos a usar (100% = todos los disponibles)\n",
    "    thin                = 10                        # (int) Frecuencia de guardado de configuraciones (1 = cada sweep, 2 = cada 2 sweeps, etc.)     \n",
    "    Boundary_conditions = True                      # (bool) Condiciones de frontera (True = eje \"y\" limitado, False = periódicas)\n",
    "    max_window          = 1000                      # (int) Ventana de datos para la tasa de aceptación (número de sweeps a considerar para calcular la pendiente de la tasa de aceptación)\n",
    "    threshold           = 10**-8                    # (float) Umbral de pendiente para aceptar la tasa de aceptación (si la pendiente es menor que este valor, se acepta)\n",
    "    Asimmetric          = True                      # (bool) Densidad de espines asimetricamente distribuidos\n",
    "    \n",
    "    # ─── Parámetros de usuario para la generación del vídeo ────────────────────────────────────────────────────────────\n",
    "\n",
    "    HDF5_FILE = \"configs.h5\"                    # Nombre del archivo HDF5 con las configuraciones\n",
    "    DATASET   = \"configs\"                       # Nombre del dataset dentro del archivo HDF5\n",
    "    FILE_OUT  = \"simulacion\"                    # Nombre del archivo de salida (sin extensión ni ruta)\n",
    "    GPU_ID    = 0                               # 0 = tu NVIDIA 4050\n",
    "    INTERVAL  = 50                              # ms entre frames → fps = 1000/INTERVAL\n",
    "    TARGET_size  = 1440                         # Tamaño del vídeo de salida (1440p, 1080p, etc.)\n",
    "    MIN_SIDE  = 160                             # mínimo seguro para NVENC (≥ 145 y par)\n",
    "\n",
    "    # Hemos reducido todo el programa a una sola función que recibe todos los parámetros necesarios.\n",
    "    # Ahora podemos ejecutar múltiples simulaciones con diferentes parámetros y \n",
    "    # vamos a preparar una secuencia de opciones para el usuario, \n",
    "    # para que vaya eligiendo qué tipo de simulación quiere hacer.\n",
    "\n",
    "        \n",
    "\n",
    "    if not os.path.exists(\"results\"):\n",
    "        os.makedirs(\"results\")\n",
    "    destino_base = os.path.join(\"results\", f\"Simulacion_Multiple\")\n",
    "    destino = destino_base\n",
    "    counter = 1\n",
    "    while os.path.exists(destino):\n",
    "        destino = f\"{destino_base}_({counter})\" \n",
    "        counter += 1\n",
    "    os.makedirs(destino)  # Crear una carpeta de destino única\n",
    "\n",
    "    # Ahora inicializamos los parámetros de temperatura:\n",
    "    T_init = 2.00                                           # Temperatura inicial\n",
    "    T_step = 0.125                                          # Paso de temperatura\n",
    "    T_max  = 2.50                                           # Temperatura máxima\n",
    "\n",
    "    # Ahora hacemos lo mismo con L:\n",
    "\n",
    "    L_init = 16                                                                     # Tamaño de red inicial\n",
    "    L_step = 4                                                                      # Paso de tamaño de red\n",
    "    L_max  = 20                                                                     # Tamaño de red máximo\n",
    "\n",
    "    \n",
    "    n_temps = int(np.rint((T_max - T_init) / T_step)) + 1                                # Número de temperaturas a simular\n",
    "    n_Ls = int(np.rint((L_max - L_init) / L_step)) + 1                                      # Número de tamaños de red a simular\n",
    "\n",
    "    # Inicializamos los arrays que vamos a usar para almacenar los resultados de las simulaciones.\n",
    "    mean_energies_per_particle = np.zeros((n_temps, n_Ls))                          # Inicializar un array para almacenar la energía media por partícula\n",
    "    SH = np.zeros((n_temps, n_Ls))                                                  # Inicializar un array para almacenar la capacidad calorífica\n",
    "    MS = np.zeros((n_temps, n_Ls))                                                  # Inicializar un array para almacenar la susceptibilidad magnética (media de los 2 dominios)\n",
    "    magnetization_vs_temp = np.zeros((n_temps, n_Ls, 2))                            # Inicializar un array para almacenar la magnetización frente a la temperatura\n",
    "    dict_densities = {}                                                             # Inicializar un diccionario para almacenar las densidades de partículas\n",
    "    L = L_init                                                                      # Inicializar el tamaño de la red\n",
    "    j = 0                                                                           # Inicializar el contador de iteraciones para el tamaño de la red\n",
    "\n",
    "\n",
    "    # Ahora sí, metemos el bucle que ejecutará las simulaciones.\n",
    "    start_time = time.time()                                                        # Medir el tiempo de ejecución total\n",
    "    for j in range(n_Ls):\n",
    "\n",
    "        L = L_init + j * L_step\n",
    "        density_y = np.zeros((n_temps, L))                                         # Inicializar un array para almacenar la densidad de partículas a lo largo de la dirección y\n",
    "        for i in range(n_temps):                                                           # Por ejemplo, de 0.5 a 5.0 en incrementos de 0.5\n",
    "\n",
    "            T = T_init + i * T_step\n",
    "            # Ahora llamamos a la función general, que nos devuelve los observables en formato array, sin necesidad de acceder a los archivos uno a uno.\n",
    "            observables = run_whole_simulation(L, J, T, n_sweeps, threads_percentage, thin, Boundary_conditions, density, destino, max_window, threshold, Asimmetric, HDF5_FILE, DATASET, FILE_OUT, GPU_ID, INTERVAL, TARGET_size, MIN_SIDE)\n",
    "            density_y[i, :] = observables['density']  # Guardar la densidad de partículas a lo largo de la dirección y en el array\n",
    "            mean_energies_per_particle[i, j] = observables['mean_energy_per_particle']  # Guardar la energía media por partícula\n",
    "            SH[i, j] = specific_heat(observables['energy'], T, L)  # Calcular el calor específico y guardarlo\n",
    "            MS[i, j] = magnetic_susceptibility(observables['domain_magnetization'], T, L)  # Calcular la susceptibilidad magnética y guardarla\n",
    "            magnetization_vs_temp[i, j, :] = observables['domain_magnetization'][:, -1]\n",
    "\n",
    "        dict_densities[f'Density_L{L}'] = density_y                                 # Guardar la densidad de partículas en el diccionario\n",
    "    end_time = time.time()                                                          # Medir el tiempo de ejecución total\n",
    "\n",
    "    # Ahora tenemos un array de densidades de partículas a lo largo de la dirección y, que se ha ido llenando a medida que hemos ido haciendo las simulaciones.\n",
    "\n",
    "    if not os.path.exists(os.path.join(destino, \"Observables\")):\n",
    "        Carpeta_Observables = os.path.join(destino, \"Observables\")\n",
    "        os.makedirs(Carpeta_Observables)\n",
    "    \n",
    "    plot_density_y(dict_densities, T_init, T_step, L_init, L_step, Carpeta_Observables)                             # Graficar la densidad de partículas a lo largo de la dirección y para cada temperatura                 \n",
    "    plot_mean_energy_per_particle(mean_energies_per_particle, T_init, T_step, L_init, L_step, Carpeta_Observables)  # Graficar la energía media por partícula para cada temperatura\n",
    "    plot_specific_heat(SH, T_init, T_step, L_init, L_step, Carpeta_Observables)                                     # Graficar el calor específico para cada temperatura\n",
    "    plot_susceptibility(MS, T_init, T_step, L_init, L_step, Carpeta_Observables)                                    # Graficar la susceptibilidad magnética para cada temperatura\n",
    "    plot_magnetizations_vs_temp(magnetization_vs_temp, T_init, T_step, L_init, L_step, Carpeta_Observables)         # Graficar la magnetización frente a la temperatura\n",
    "\n",
    "    # Ahora hay que dar el valor de la temperatura crítica en función de L.\n",
    "    # Para esto buscamos la temperatura donde se produce el pico de calor específico.\n",
    "    T_crit_L_SH = np.zeros(n_Ls)                                                    # Array para almacenar la temperatura crítica para cada tamaño de red\n",
    "    for j in range(n_Ls):\n",
    "        T_crit_L_SH[j] = T_init + np.argmax(SH[:, j]) * T_step                      # La temperatura crítica es la temperatura donde el calor específico es máximo\n",
    "    filenameSH = \"Tcrit_L_SH.png\"                                                   # Nombre del archivo donde se guardará la gráfica de la temperatura crítica en función del tamaño de la red\n",
    "\n",
    "    # Ahora ploteamos la temperatura crítica derivada de la capacidad calorífica.\n",
    "    plot_Tcrit_L(T_crit_L_SH, L_init, L_step, Carpeta_Observables, filenameSH)      # Graficar la temperatura crítica en función del tamaño de la red\n",
    "\n",
    "    T_crit_L_MS = np.zeros(n_Ls)                                                    # Array para almacenar la temperatura crítica para cada tamaño de red\n",
    "    for j in range(n_Ls):\n",
    "        T_crit_L_MS[j] = T_init + np.argmax(MS[:, j]) * T_step                      # La temperatura crítica es la temperatura donde la susceptibilidad magnética es máxima\n",
    "    filenameMS = 'Tcrit_L_MS.png'\n",
    "\n",
    "    # Ahora ploteamos la temperatura crítica derivada de la susceptibilidad magnética.\n",
    "    plot_Tcrit_L(T_crit_L_MS, L_init, L_step, Carpeta_Observables, filenameMS)      # Graficar la temperatura crítica en función del tamaño de la red\n",
    "    \n",
    "    print(f\"Simulación completada en {end_time - start_time:.2f} s\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2709a3",
   "metadata": {},
   "source": [
    "Como vemos, en esta última celda es donde damos valor a todas las variables, y desde aquí podemos configurar todas las distintas opciones. Ahora que hemos visto cómo funciona el programa a nivel interno, veamos los resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f3eb7a",
   "metadata": {},
   "source": [
    "## Resultados y discusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ec654",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ising-kawasaki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
